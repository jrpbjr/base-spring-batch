## Como executar üíª

Aqui est√° um guia b√°sico para executar este projeto em seu ambiente de desenvolvimento:

### Passo 1 - Clone o Reposit√≥rio

Primeiro, clone o projeto a partir do reposit√≥rio do GitHub. Use um dos seguintes comandos, dependendo da forma de
acesso escolhida:

```bash
git clone git@github.com:Eduardobalan/estudo-spring-batch.git
```

ou

```bash
git clone https://github.com/Eduardobalan/estudo-spring-batch.git
```

### Passo 2 - Configura√ß√£o na Sua IDE

Certifique-se de importar o projeto para a sua IDE favorita. Isso permitir√° que voc√™ fa√ßa as configura√ß√µes necess√°rias e
trabalhe com o c√≥digo com facilidade.

### Passo 3 - Iniciando os Containers Docker

Para executar o projeto, √© necess√°rio iniciar dois containers Docker com bancos de dados PostgreSQL.
Para fazer isso, execute o seguinte comando a partir da pasta raiz do reposit√≥rio:

```bash
docker-compose up -d
```

Isso iniciar√° os bancos de dados necess√°rios para o funcionamento do projeto.

### Passo 4 - Configura√ß√£o Autom√°tica ao subir seu projeto.

Quando voc√™ executa o projeto pela primeira vez, v√°rias a√ß√µes ser√£o executadas automaticamente:

- O Hibernate criar√° as entidades necess√°rias para ambos os bancos de dados.
- O MigrarBancoSpringBatchCommandLineRunner inserir√° as tabelas do Spring Batch.
- O MigrarCargaOrigemCommandLineRunner preencher√° automaticamente o banco de dados de origem (DB_ORIGEM) com registros
  de exemplo.

### Passo 5 - Execu√ß√£o dos Jobs via Requisi√ß√£o HTTP

O projeto oferece um √∫nico ponto de entrada para a execu√ß√£o de Jobs:

- http://localhost:8081/startJobs/{jobName}/{jobId}

#### Substitua as vari√°veis Path:

**{jobName}**: Coloque o nome do job desejado ('JOB_MIGRAR_PESSOA_DESTINO' ou '
JOB_VISUALIZAR_CICLO_DE_VIDA_SPRING_BATCH').

**{jobId}**: Insira um identificador √∫nico. Se voc√™ usar o mesmo identificador, o Spring Batch tentar√° continuar a
execu√ß√£o anterior.
______________________________________________________________________________________________________________________

#### Executando o Job JOB_MIGRAR_PESSOA_DESTINO

Neste job inicial, a migra√ß√£o de dados √© executada, onde os dados s√£o extra√≠dos de uma tabela de origem (tb_pessoa) e
inseridos nas tabelas de destino (tb_pessoa_destino e tb_usuario_destino).
Embora este job possa parecer direto, h√° diversas configura√ß√µes essenciais dentro da pasta de configura√ß√£o do
aplicativo (application/configuration).
Estas configura√ß√µes s√£o cruciais para informar o Spring sobre quais entidades (Entitys) e reposit√≥rios (repositorys)
est√£o vinculados a quais bases de dados, e apesar de serem ocultas, desempenham um papel fundamental no processo de
migra√ß√£o de dados.

Use o seguinte comando curl para iniciar o Job 'JOB_MIGRAR_PESSOA_DESTINO':

```bash
curl --request POST   --url http://localhost:8081/startJobs/JOB_MIGRAR_PESSOA_DESTINO/1 --header 'Content-Type: application/json' --data '{}'
```

______________________________________________________________________________________________________________________

#### Executando o Job JOB_VISUALIZAR_CICLO_DE_VIDA_SPRING_BATCH

Este job realiza o mesmo procedimento do JOB_MIGRAR_PESSOA_DESTINO, por√©m, nele foram incorporados v√°rios listeners do
Spring.
Esses listeners auxiliam na compreens√£o do ciclo de vida completo de um job no Spring Batch, abrangendo as etapas do job
e as intera√ß√µes com seus ouvintes (listeners).

Para iniciar o Job 'JOB_VISUALIZAR_CICLO_DE_VIDA_SPRING_BATCH', utilize o seguinte comando curl:

```bash
curl --request POST   --url http://localhost:8081/startJobs/JOB_VISUALIZAR_CICLO_DE_VIDA_SPRING_BATCH/2 --header 'Content-Type: application/json' --data '{}'
```

______________________________________________________________________________________________________________________

#### Executando o Job JOB_UTILIZANDO_CONTEXT

Neste exemplo, investigamos a utiliza√ß√£o do contexto no Spring Batch para esclarecer o funcionamento dos contextos de
step e job.
Em um job composto por 3 steps, inserimos informa√ß√µes tanto no **StepExecutionContext** quanto no **JobExecutionContext
**. No terceiro step,
ao tentar recuperar essas informa√ß√µes, notamos que o valor salvo no **StepExecutionContext** n√£o est√° dispon√≠vel, uma
vez que esse contexto existe apenas para a execu√ß√£o de um step espec√≠fico.
No entanto, observamos que o **JobExecutionContext** mant√©m suas vari√°veis intactas.

Essa distin√ß√£o √© valiosa em cen√°rios onde desejamos compartilhar informa√ß√µes entre etapas de um job e persistir dados
para poss√≠veis reinicializa√ß√µes.
O JobExecutionContext pode ser √∫til para armazenar dados de alto n√≠vel, compartilhados entre v√°rias etapas do job,
enquanto o StepExecutionContext √© ideal para informa√ß√µes espec√≠ficas de uma etapa individual.
Isso permite uma maior flexibilidade e controle ao gerenciar o fluxo de trabalho do Spring Batch, garantindo que os
dados estejam dispon√≠veis onde e quando s√£o necess√°rios.

Para iniciar o Job 'JOB_UTILIZANDO_CONTEXT', utilize o seguinte comando curl:

```bash
curl --request POST   --url http://localhost:8081/startJobs/JOB_UTILIZANDO_CONTEXT/2 --header 'Content-Type: application/json' --data '{}'
```

______________________________________________________________________________________________________________________

#### Executando o Job JOB_MIGRAR_PESSOA_E_USUARIO_CRIANDO_VINCULO

Neste exemplo, adotamos um StepExecutionListener com a anota√ß√£o @StepScope para renovar seu contexto a cada execu√ß√£o de
um novo step. Dentro deste StepExecutionListener, realizamos um carregamento de um Map<Long, Long> que armazena
informa√ß√µes do ID do banco antigo e do ID do banco novo. Com isso, incorporamos o StepExecutionListener via @Autowired
no nosso processer, concedendo-nos acesso a um mapeamento de IDs antigos para novos. Essa abordagem evita a necessidade
de acessar o banco a cada execu√ß√£o do processer para descobrir a origem do ID, reduzindo consideravelmente a frequ√™ncia
de opera√ß√µes de entrada e sa√≠da (I/O) a cada itera√ß√£o do processer.

Para iniciar o Job 'JOB_MIGRAR_PESSOA_E_USUARIO_CRIANDO_VINCULO', utilize o seguinte comando curl:

```bash
curl --request POST   --url http://localhost:8081/startJobs/JOB_MIGRAR_PESSOA_E_USUARIO_CRIANDO_VINCULO/55 --header 'Content-Type: application/json' --data '{}'
```

______________________________________________________________________________________________________________________

#### Executando o Job JOB_MIGRAR_PESSOA_COMPOSITE

Neste exemplo, estamos utilizando o **CompositeItemProcessor** e **CompositeItemWriter** para compreender o seu
comportamento. Esses compositores s√£o empregados para agregar m√∫ltiplos **ItemProcessor** ou **ItemWriter**,
respectivamente. Normalmente, os composites s√£o inseridos em um Step como Processor ou Writer.

O **CompositeItemProcessor** opera de acordo com o pattern 'change of responsibility', no qual cada item passa por todos
os ItemProcessor at√© chegar ao final da cadeia.
√â crucial observar que essa abordagem pode potencialmente gerar erros em tempo de execu√ß√£o, pois o tipo de sa√≠da
gen√©rico de um ItemProcessor deve corresponder ao tipo de entrada do pr√≥ximo ItemProcessor. Al√©m disso, o √∫ltimo
ItemProcessor deve produzir a sa√≠da esperada pelo ItemWriter. Portanto, a ordem de inser√ß√£o no CompositeItemProcessor √© 
fundamental para garantir o fluxo correto.

O **CompositeItemWriter** possui uma din√¢mica mais simples. Cada ItemWriter √© chamado para receber a lista
dos itens processados na mesma sequ√™ncia em que foram inseridos no CompositeItemWriter.

Para iniciar o Job 'JOB_MIGRAR_PESSOA_COMPOSITE', utilize o seguinte comando curl:

```bash
curl --request POST   --url http://localhost:8081/startJobs/JOB_MIGRAR_PESSOA_COMPOSITE/100 --header 'Content-Type: application/json' --data '{}'
```

______________________________________________________________________________________________________________________


Agora, voc√™ pode facilmente agendar a execu√ß√£o dos Jobs desejados por meio de requisi√ß√µes HTTP.
Lembre-se de que a requisi√ß√£o HTTP apenas agendar√° a execu√ß√£o e n√£o retornar√° uma resposta direta ap√≥s o agendamento
bem-sucedido.
Para monitorar e compreender melhor a execu√ß√£o do projeto, esteja atento ao log da aplica√ß√£o e √†s altera√ß√µes nas tabelas
de banco de dados relacionadas aos Jobs.
Isso fornecer√° insights essenciais sobre o progresso e o funcionamento do projeto.